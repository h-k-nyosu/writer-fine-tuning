# Fine-tuning:gpt-3.5-turboの活用事例。絵文字分類タスク改善のプロセスと、学びの言語化。
みなさん、Fine-tuning使ってますか！？
一週間ほど前に、OpenAI社からgpt-3.5-turboがFine-tuning可能になったとのアップデートがありましたね。
ニュースを見て凄そうと思いつつ、少し作業のハードルがあったり、プロンプトエンジニアリングで事足りてるから、そんなに使わないかも？🤔と思ってました。
ただ今回、重い腰を上げて、Fine-tuningを試してみたら、想像以上の結果が得られたので、そのプロセスと学びをまとめます！
システムに組み込む際の Prompt Engineering で苦戦している皆さん、Fine-tuningはかなり希望になると思います…！これからはPromptをゴニョゴニョするよりも、Fine-tuningに力を入れていこうと思いました。
ではまとめていきます！

## 前置きとこれまでの課題
今回は、音声メモ日記アプリ「シャべマル」の絵文字分類タスクにFine-tuningを活用して改善を試みました。「シャべマル」については以下の記事で紹介してます。
簡単にいうと、メモ内容にマッチする絵文字を、ChatGPTなどを駆使して自動的に紐づける機能があります。現在の仕組みとしてはこんな感じです。
前提として、絵文字は商用利用の関係からUnicodeで表現されるものではなく、絵文字の画像データを用いています。なので最終的に画像ファイル名を1つ選択し、それを表示しています。
処理の流れとしては、メモ内容からトピック（単語）をFunction Callingを用いて生成し、それをベクトルに変換。
そして、あらかじめ準備してある「絵文字ラベルのベクトル（1364種類）」と「トピックのベクトル」の類似度を計算して、絵文字ラベルを選定する形をとっています。

Q. なぜ一度トピック生成を挟んでいるのか？🤔
A. 理由は主に2つあります！👋
メモ内容を直接ベクトル変換し、絵文字ベクトルと類似度計算をして、最も内容に近い絵文字を選定するも、失敗。
これはかなり精度が悪かったです…。長文だと様々なテーマが含まれており、関係のない絵文字ばかりが選定されました。

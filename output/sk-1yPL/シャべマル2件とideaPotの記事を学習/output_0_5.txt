考察としては、大量の絵文字ラベルを詰め込んだため、systemメッセージの情報量が膨大となってしまったためinstruct-input-outputの関係性が掴めにくかったのかなと思ってます。
感覚としては、そのプロンプトはgpt-3.5-turboと会話する時に上手くいきそうか？みたいな判断基準が当てはまりそうな気がしています。結局モデルはプロンプトの最初と最後に注目が当たっているということなので、多すぎても理解されないみたいな。
Few-shot的な感じで、10件程度ずつ取り込んでいけばまた変わったかもしれないです。お金に余裕がないので、検証としてはここで断念です💸

### Fine-tuningモデルを使ってデータセット数を増やしてみた
n_epoch=9でFine-tuningしたモデルによる絵文字ラベリングは、人間の目から見ても遜色ない（むしろ良い）形で実現できた感があります。
そこで新たにFine-tuningモデルで作った、メモと絵文字のデータセットを100件加えてみました！
もちろんメモは新たに100件を新規作成し、それを自動で絵文字ラベリングしたものを、人の目で再度見返してブラッシュアップしています。
データセット数を増やすことで、さらに精度が向上するかなと考えたのですが、結果としては残念な形に。出力結果が絵文字Unicodeとなり、絵文字ラベル名ではありませんでした。Fine-tuning失敗です😇
完全に精度向上すると思いきや失敗したので、なんでだろうと気になり原因の切り分けをしてみました。
すると、AIでラベリングしたデータセット100件のみを利用して学習させた場合でも同様の絵文字Unicodeが出力される結果となりました。
つまり、データセット数が増えたことが問題ではなく、AIによってラベリングしたもの（数件は人の手で修正してます）を使ったことが原因で、上手くいかなかったみたいです。
これに関してはちょっと何でなのか分からないですね。今後うまくいかなかった場合の判断材料として頭の隅に置いておこうと思います。

### データセットのファイル管理ミス

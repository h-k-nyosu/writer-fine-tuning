※ちなみにFine-tuning後は、プロンプトで絵文字ラベル名について一切教えていません。なのにこの安定具合はすごい👏※9割の成功確率であっても、最終的に最も類似するものをシステム的に1つ選択するので、絵文字が表示されないということはありません！
ということで、想定を超える結果とポテンシャルを感じさせてくれました！絵文字の精度が上がったメモアプリ「シャべマル」をぜひ試してみてください。

さて、ここからは Fine-tuning のプロセスと、そこから得られた学びや考察をまとめていきます。テクニカルな内容が多めになります。

## Fine-tuningのプロセスと学び
基本的なやり方については、以下の記事がかなり分かりやすくまとめられているので参考にしてみてください。
この記事では、今回の絵文字分類タスクにおけるデータセット作成方法と、epoch数ごとの挙動の変化、そのほか上手くいかなかった失敗事例に焦点を当ててまとめていきます。
### データセット作成
やりたいこととしては、メモ内容（Input）→絵文字ラベル（Output）です。なので、この教師データを作成する必要があります。以下の手順で行いました！
まずメモのテーマを100個生成（メモ内容にばらつきを持たせるため）
各テーマをベースに、日常生活で記録されるような200文字程度のメモを gpt-3.5-turbo で100個生成
100個のメモを、人力で絵文字ラベリングする💪
地道ですが、ここが結構鍵を握ってる感じがありました。
基本的に、ここで絵文字ラベリングしたものをgpt-3.5-turboは学習する形になります。またラベル名からは拾えない人間の直感的な印象も、このデータセットを通して学習させることができる感じがします！
例えば、有名人と出会えた → ✨ 産まれたてのちっちゃい可愛い動物がいた → 🐣

### 学習用データセット形式へ変換
先ほど作ったデータセットを、学習用データセットの形式に整えます。形式は普段のAPIコールと似ていて、system, user, assistantメッセージの形式で作られた会話集を複数作るイメージです。

そんなこんなで、作ったデータセットをアップロードします！

### Fine-tuningジョブを作成

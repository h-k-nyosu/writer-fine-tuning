Fine-tuningのジョブ作成は比較的簡単です。こんな感じで作成できます！
入力するのは、
training_file - ファイルをアップロードのレスポンスで得られた`id`model - ここでは`gpt-3.5-turbo-0613`hyperparameters - n_epochsのみ指定可能 - 任意項目。ドキュメントを見ると`n_epochs: auto`も設定できるみたいですね（今知りました。デフォルトはautoかな？）suffix - fine-tuning model idの識別を容易にする文字列（任意）
他にもvalidation関連の項目はありますが、絵文字分類タスクは正解のない曖昧なタスクなので難しいなーと思い、省略してます。
今回の試行では、同一ファイル（データセット）を用いて n_epochs を1, 3, 6, 8, 9, 10の合計6回実行しました！パラメータを変えるだけで、様々なモデルが作成できて、Fine-tuningモデルの比較ができる体験はかなり良かったです✨
ジョブを作成したら、出来上がりを待ちます！（メール届きます）
進捗を確認したい場合は、以下のように実行できます（python）

### 各Fine-tuningモデルの検証
結果的に、n_epochs={1, 3, 6, 8, 9, 10}の6パターンのモデルが出来上がりました！これらについて、以下の観点から検証していきます。
出力形式は"絵文字ラベル名のみ"になっているか？
メモ内容を理解し、それに合わせた納得感のある絵文字を選定してくれているか？（サービス体験改善に向けた今回の本目的）

まず全体的に、出力結果は絵文字ラベルのような英語の文字列を出力してくれました。出力形式を強制する効果はepoch=6くらいから強く見られた感じがします。
また、epoch数を増やしていくほど、存在する絵文字ラベルを出力をしてくれる精度が高まりました！ただし、epoch=9を上限に、epoch=10からは精度の悪化が見られました。これは謎です…（笑）
あと少し驚いたのが、学習用データセットで教え込んでいない絵文字についても推測して生成しているケースがありました。
